![TorchFormer-Logo](docs/logo.jpg "TorchFormer")

# TorchFormer

This repository is an exploratory implementation of transformers in PyTorch.
The implementation is based on the original transformer architecture proposed in the paper [Attention is All You Need](https://arxiv.org/abs/1706.03762).
